# ğŸ  SPD ImÃ³veis - Sistema Inteligente de Busca SemÃ¢ntica

Um sistema completo de busca semÃ¢ntica de imÃ³veis com reranking inteligente baseado em LLM, desenvolvido com FastAPI, Streamlit e ChromaDB.

## ğŸ¯ CaracterÃ­sticas Principais

- **ğŸ” Busca SemÃ¢ntica**: Encontre imÃ³veis usando linguagem natural
- **ğŸ¤– Reranking Inteligente**: IA analisa suas preferÃªncias com Gemma3 4B
- **ğŸ“Š Interface Moderna**: Dashboard intuitivo em Streamlit
- **âš¡ Performance**: VectorizaÃ§Ã£o com ChromaDB + embeddings otimizados
- **ğŸ³ ContainerizaÃ§Ã£o**: Deploy simplificado com Docker
- **ğŸ”„ IntegraÃ§Ã£o**: API REST completa com documentaÃ§Ã£o automÃ¡tica

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚â”€â”€â”€â”€â”‚   FastAPI       â”‚â”€â”€â”€â”€â”‚   ChromaDB      â”‚
â”‚   (Frontend)    â”‚    â”‚   (Backend)     â”‚    â”‚   (Vectors)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB       â”‚â”€â”€â”€â”€â”‚   Redis         â”‚â”€â”€â”€â”€â”‚   Ollama LLM    â”‚
â”‚   (Database)    â”‚    â”‚   (Cache)       â”‚    â”‚   (AI)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Tecnologias Utilizadas

### Backend
- **FastAPI**: Framework web moderno e rÃ¡pido
- **Python 3.11**: Linguagem principal
- **ChromaDB**: Banco de dados vetorial para busca semÃ¢ntica
- **MongoDB**: Armazenamento de dados estruturados
- **Redis**: Cache e fila de tarefas
- **Sentence Transformers**: GeraÃ§Ã£o de embeddings

### IA e Machine Learning
- **Ollama**: Servidor local de LLM
- **Gemma3 4B**: Modelo de linguagem para reranking
- **all-MiniLM-L6-v2**: Modelo de embedding semÃ¢ntico
- **CUDA**: AceleraÃ§Ã£o GPU (opcional)

### Frontend
- **Streamlit**: Interface web interativa
- **Plotly**: VisualizaÃ§Ãµes e grÃ¡ficos
- **Bootstrap**: Componentes UI responsivos

### DevOps
- **Docker**: ContainerizaÃ§Ã£o
- **Docker Compose**: OrquestraÃ§Ã£o de serviÃ§os
- **GitHub Actions**: CI/CD (configurÃ¡vel)

## ğŸ“‹ PrÃ©-requisitos

- **Docker** e **Docker Compose** instalados
- **8GB RAM** disponÃ­vel (6GB para Gemma3 4B + 2GB sistema)
- **5GB espaÃ§o em disco** (modelo + dados)
- **Ollama instalado localmente** com Gemma3 4B

### InstalaÃ§Ã£o do Ollama Local

```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar Gemma3 4B
ollama pull gemma3:4b

# Verificar instalaÃ§Ã£o
ollama list
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone <repo-url>
cd SPD-Imoveis
```

### 2. Configurar Dados

O sistema busca automaticamente o diretÃ³rio `anuncios_salvos` em:

```
../anuncios_salvos          # DiretÃ³rio pai do projeto
./anuncios_salvos           # Dentro do projeto  
~/SPD/anuncios_salvos       # Home do usuÃ¡rio
```

**Ou defina manualmente:**
```bash
export ANUNCIOS_SALVOS_PATH="/caminho/para/anuncios_salvos"
```

### 3. Estrutura dos Dados

```
anuncios_salvos/
â”œâ”€â”€ 1/
â”‚   â”œâ”€â”€ info.json
â”‚   â””â”€â”€ imagem_*.jpg
â”œâ”€â”€ 2/
â”‚   â”œâ”€â”€ info.json
â”‚   â””â”€â”€ imagem_*.jpg
â””â”€â”€ ...
```

### 4. Inicializar Sistema

```bash
# Subir todos os serviÃ§os
docker-compose up -d

# Aguardar inicializaÃ§Ã£o (30-60 segundos)

# Carregar dados e testar
python init_and_test_system.py
```

## ğŸŒ Acesso ao Sistema

| ServiÃ§o | URL | DescriÃ§Ã£o |
|---------|-----|-----------|
| ğŸ–¥ï¸ **Interface Principal** | http://localhost:8501 | Dashboard Streamlit |
| ğŸ“š **API Documentation** | http://localhost:8001/docs | Swagger/OpenAPI |
| ğŸ” **API Endpoint** | http://localhost:8001/search | Busca semÃ¢ntica |
| ğŸ¤– **Ollama Local** | http://localhost:11434 | Servidor LLM |

## ğŸ’¡ Como Usar

### 1. Busca BÃ¡sica

1. Acesse http://localhost:8501
2. Digite sua busca: "apartamento 2 quartos Bueno"
3. Veja os resultados rankeados por relevÃ¢ncia

### 2. Reranking Inteligente

1. FaÃ§a uma busca inicial
2. Clique em â¤ï¸ (gostei) ou âŒ (nÃ£o gostei) nos imÃ³veis
3. O sistema aprende suas preferÃªncias
4. Receba sugestÃµes personalizadas com IA

### 3. API REST

```bash
# Busca simples
curl "http://localhost:8001/search/?query=casa+3+quartos&n_results=10"

# Reranking com preferÃªncias
curl -X POST "http://localhost:8001/rerank/" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "apartamento bueno",
    "liked_properties": [...],
    "disliked_properties": [...],
    "remaining_properties": [...]
  }'
```

## ğŸ§  Funcionamento da IA

### Busca SemÃ¢ntica
1. **Entrada**: Query em linguagem natural
2. **Embedding**: ConversÃ£o para vetor 384D
3. **Similaridade**: Busca coseno no ChromaDB
4. **Ranking**: OrdenaÃ§Ã£o por relevÃ¢ncia

### Reranking Inteligente
1. **AnÃ¡lise**: Gemma3 4B analisa preferÃªncias do usuÃ¡rio
2. **Context**: HistÃ³rico de likes/dislikes
3. **Reasoning**: ExplicaÃ§Ã£o das escolhas
4. **Output**: JSON estruturado com recomendaÃ§Ãµes

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

```bash
# API Configuration
MONGO_CONNECTION_STRING=mongodb://localhost:27017/
CHROMA_HOST=localhost
CHROMA_PORT=7777
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

# LLM Configuration
OLLAMA_KEEP_ALIVE=10m
OLLAMA_CONTEXT_LENGTH=4096
OLLAMA_NUM_GPU=1  # Para usar GPU
```

### Performance

- **GPU**: Configure `OLLAMA_NUM_GPU=1` para aceleraÃ§Ã£o
- **MemÃ³ria**: Ajuste `memory` limits no docker-compose.yml
- **Cache**: Redis otimiza consultas repetidas
- **Embedding**: Modelo prÃ©-treinado para portuguÃªs

## ğŸ› Troubleshooting

### Problemas Comuns

**âŒ "Erro de conexÃ£o com API"**
```bash
# Verificar se API estÃ¡ rodando
curl http://localhost:8001/
docker logs api -f
```

**âŒ "Parse da resposta LLM falhou"**
```bash
# Verificar se Ollama estÃ¡ ativo
ollama list
curl http://localhost:11434/api/tags
```

**âŒ "anuncios_salvos nÃ£o encontrado"**
```bash
# Definir path manualmente
export ANUNCIOS_SALVOS_PATH="/seu/caminho"
```

### Logs e Debug

```bash
# Ver logs de todos os serviÃ§os
docker-compose logs -f

# Log especÃ­fico de um serviÃ§o
docker logs api -f
docker logs spd_streamlit -f

# Debug da API
export DEBUG=true
```

## ğŸ“Š MÃ©tricas e Monitoramento

- **Tempo de Resposta**: < 200ms para buscas
- **AcurÃ¡cia**: Similarity score > 0.7
- **Throughput**: 100+ consultas/minuto
- **Cache Hit Rate**: 80%+ com Redis

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -m 'Add nova funcionalidade'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra Pull Request


**ğŸ  SPD ImÃ³veis** - Encontre seu imÃ³vel ideal com inteligÃªncia artificial